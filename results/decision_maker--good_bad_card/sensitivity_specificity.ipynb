{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring sensitivity and specificity into the Categorize Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this operational research activity was to measure the **specificity** (% of **good samples** identified as good) and **sensitivity** (% of **bad samples** identified as bad) of the PAD test.  There were similar numbers of good and bad samples, so **accuracy** is the average of specificity and sensitivity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of bad samples\n",
    "### Bad samples\n",
    "\n",
    "```\n",
    "SELECT * FROM `Analysis` WHERE `sample_name`!=`sample_actual` \n",
    "\n",
    "```\n",
    "### Bad samples considering one class\n",
    "\n",
    "```\n",
    "SELECT * FROM `Analysis` WHERE `sample_name`!=`sample_actual` AND `sample_name`=\"Amoxicillin\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Sample List of the categorize set \n",
    "\n",
    "```\n",
    "./categorize_good_bad_samples.csv\n",
    "```\n",
    "| good/bad | id_actual | id_written | sample_actual | sample_name | proc_file_location |\n",
    "| -------- | --------- | ---------- | ------------- | ----------- | ------------------ |\n",
    "| good | 9 | 9 | Paracetamol| Paracetamol | /var/www/html/joomla/images/padimages/msh/processed/Analyst_30-12LanePADKenya2015-1-11771.processed.png |\n",
    "| bad | 2 | 1 | Starch | Penicillin Procaine | /var/www/html/joomla/images/padimages/msh/processed/35612.processed.png |\n",
    "| good | 8 | 8 | Benzyl <br>Penicillin | Benzyl <br>Penicillin | /var/www/html/joomla/images/padimages/msh/processed/Analyst_30-12LanePADKenya2015-1-3812.processed.png |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_labels(fn):\n",
    "    try:\n",
    "        d_file = open(fn, \"r\")\n",
    "        d_lines = d_file.readlines()\n",
    "    except:\n",
    "        print(\"Missing file.\")\n",
    "        exit(-1)\n",
    "\n",
    "    sample_labels = {} \n",
    "    for dl in d_lines:\n",
    "        dl = dl.rstrip('\\n')\n",
    "        data = dl.split(\",\")\n",
    "        \n",
    "        try:\n",
    "            proc_file_location = data[-1]\n",
    "            sample_labels[proc_file_location] =  data[0:]\n",
    "        except:\n",
    "            continue\n",
    "    return sample_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group samples by sample_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sample_name = {}\n",
    "samples_by_id_name = {}\n",
    "img_locations = {}\n",
    "\n",
    "sample_labels = get_sample_labels(\"groundtruth_good_bad_cards/categorize_good_bad_samples.csv\")\n",
    "\n",
    "#fill in dictionary\n",
    "for sample in sample_labels :\n",
    "    #is_good = 1 if(sample_labels[sample][0]==\"good\") else 0\n",
    "    is_good = sample_labels[sample][0]\n",
    "    id_actual = int(sample_labels[sample][1])\n",
    "    id_name = int(sample_labels[sample][2])\n",
    "    sample_actual = sample_labels[sample][3]\n",
    "    sample_name = sample_labels[sample][4] \n",
    "    proc_file_location = sample_labels[sample][5]\n",
    "\n",
    "    # print(is_good,sample_labels[sample][0], id_name, sample_name, id_actual, sample_actual )\n",
    "    \n",
    "    # Full samples_by_id_name\n",
    "    if int(id_name) not in dict_sample_name:\n",
    "        samples_by_id_name[id_name] = {}\n",
    "        img_locations[id_name] = {}\n",
    "        img_locations[id_name]['good']= [] \n",
    "        img_locations[id_name]['bad']= [] \n",
    "    else:\n",
    "        samples_by_id_name[id_name][proc_file_location] = [ id_actual , is_good ]\n",
    "        img_locations[id_name][is_good].append(proc_file_location)\n",
    "                \n",
    "    # Full dict_sample_name\n",
    "    dict_sample_name[id_name] = sample_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read - drug or distractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_drug_labels(drug_label_fname):\n",
    "    try:\n",
    "        d_file = open(drug_label_fname, \"r\") #open(sys.argv[1], \"r\")\n",
    "        d_lines = d_file.readlines()\n",
    "    except:\n",
    "        print(\"Missing drug label file.\")\n",
    "        exit(-1)\n",
    "\n",
    "    drugs = {}\n",
    "    is_distractor = {}\n",
    "\n",
    "    #loop\n",
    "    for dl in d_lines:\n",
    "        data = dl.split(\",\")\n",
    "        try:\n",
    "            drugs[int(data[1])] = data[0]\n",
    "            is_distractor[int(data[1])] = False if(int(data[3])) else True \n",
    "        except:\n",
    "            continue\n",
    "    return drugs, is_distractor\n",
    "\n",
    "drug_label_fname = \"../../datasets/msh_tanzania_blank_drugs.csv\"\n",
    "drugs, is_distractor = read_drug_labels(drug_label_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping prediction categorize image name to proc_file_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_name_and_location(fn):\n",
    "    try:\n",
    "        d_file = open(fn, \"r\")\n",
    "        d_lines = d_file.readlines()\n",
    "    except:\n",
    "        print(\"Missing file.\")\n",
    "        exit(-1)\n",
    "\n",
    "    dict_sample_location = {}\n",
    "    for dl in d_lines:\n",
    "        dl = dl.rstrip('\\n')\n",
    "        data = dl.split(\",\")\n",
    "        try:\n",
    "            im_name = data[1].split(\"/\")[-1]\n",
    "            proc_file_location = data[2]\n",
    "            dict_sample_location[im_name] = proc_file_location\n",
    "        except:\n",
    "            continue\n",
    "    return dict_sample_location\n",
    "\n",
    "\n",
    "def read_prediction(fn):\n",
    "    try:\n",
    "        d_file = open(fn, \"r\")\n",
    "        d_lines = d_file.readlines()\n",
    "    except:\n",
    "        print(\"Missing file.\")\n",
    "        exit(-1)\n",
    "\n",
    "    dict_prediction = {}\n",
    "    for dl in d_lines:\n",
    "        dl = dl.rstrip('\\n')\n",
    "        data = dl.split(\",\")\n",
    "        try:\n",
    "            im_name = data[1].split(\"/\")[-1]\n",
    "            dict_prediction[im_name] = int(data[0])\n",
    "        except:\n",
    "            continue\n",
    "    return dict_prediction\n",
    "\n",
    "\n",
    "def get_prediction(prediction_fn, categorize_src_labels_fn): \n",
    "    \n",
    "    cat_image_name_loc = read_image_name_and_location(categorize_src_labels_fn)\n",
    "    prediction = read_prediction(prediction_fn)\n",
    "    \n",
    "    prediction_by_img_location={}\n",
    "    for img_name in cat_image_name_loc:\n",
    "        #print(img_name, prediction[img_name], cat_image_name_loc[img_name])\n",
    "        prediction_by_img_location[cat_image_name_loc[img_name]]=prediction[img_name]    \n",
    "    return prediction_by_img_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate  specificity and sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_sample_name\n",
    "# img_locations\n",
    "# samples_by_id_name => preciso apenas se quiser saber o sample_actual por localizacao da imagem   \n",
    "\n",
    "\n",
    "# Change here for different models\n",
    "\n",
    "# model G1-dt250-seed27, acc1 93.03, acc2 98.31 (only drugs)\n",
    "#categorize_src_labels_fn = \"../../datasets/1/msh_tanzania_bal-1-250/categorize/src_labels.csv\" # \"categorize_bal_1_250_src_labels.csv\"\n",
    "#prediction_fn =\"prediction_msh_tanzania_bal-1-250_27.csv\"\n",
    "\n",
    "## model G2-dt375-seed15, acc1 94.35, acc2 98.31 (only drugs) \n",
    "categorize_src_labels_fn = \"../../datasets/2/msh_tanzania_bal-2-375/categorize/src_labels.csv\"\n",
    "prediction_fn =\"prediction_msh_tanzania_bal-2-375_15.csv\"\n",
    "\n",
    "# model G2-dt400-seed10, acc1 94.54, acc2 99.32 (only drugs)\n",
    "#categorize_src_labels_fn = \"../../datasets/2/msh_tanzania_bal-2-400/categorize/src_labels.csv\"\n",
    "#prediction_fn =\"prediction_msh_tanzania_bal-2-400_10.csv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Mapping prediction categorize image name to proc_file_location\n",
    "prediction_by_img_location=get_prediction(prediction_fn, categorize_src_labels_fn)\n",
    "\n",
    "\n",
    "res_good_cards = {}\n",
    "res_bad_cards = {}\n",
    "\n",
    "for id_name in dict_sample_name:\n",
    "    if (not is_distractor[id_name]) & (dict_sample_name[id_name]==drugs[id_name]):\n",
    "        good_cards = img_locations[id_name]['good']\n",
    "        bad_cards = img_locations[id_name]['bad']\n",
    "\n",
    "        res_good_cards[id_name] = {}\n",
    "        res_bad_cards[id_name] = {}\n",
    "\n",
    "        # Sensitivity (% good as good)\n",
    "        sum_correct = 0\n",
    "        for g_card in good_cards:            \n",
    "            predicted_id = prediction_by_img_location[g_card]\n",
    "            res = 1 if (predicted_id==id_name) else 0\n",
    "            sum_correct+=res\n",
    "            \n",
    "        res_good_cards[id_name][\"total\"] = len(good_cards)\n",
    "        res_good_cards[id_name][\"correct\"] = sum_correct\n",
    "        \n",
    "        # Specificity (% bad as bad)\n",
    "        sum_correct=0\n",
    "        for g_card in bad_cards:\n",
    "            predicted_id = prediction_by_img_location[g_card]\n",
    "            res = 1 if (predicted_id!=id_name) else 0\n",
    "            sum_correct+=res\n",
    "            \n",
    "        res_bad_cards[id_name][\"total\"] = len(bad_cards)            \n",
    "        res_bad_cards[id_name][\"correct\"] = sum_correct\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benzyl Penicillin\n",
      "\tSensitivity {'total': 56, 'correct': 55} 98.21%\n",
      "\tSpecificity {'total': 46, 'correct': 46} 100.00%\n",
      "\tAccuracy 99.11%\n",
      "Paracetamol\n",
      "\tSensitivity {'total': 60, 'correct': 60} 100.00%\n",
      "\tSpecificity {'total': 46, 'correct': 44} 95.65%\n",
      "\tAccuracy 97.83%\n",
      "Amoxicillin\n",
      "\tSensitivity {'total': 45, 'correct': 45} 100.00%\n",
      "\tSpecificity {'total': 47, 'correct': 47} 100.00%\n",
      "\tAccuracy 100.00%\n",
      "Quinine\n",
      "\tSensitivity {'total': 54, 'correct': 54} 100.00%\n",
      "\tSpecificity {'total': 42, 'correct': 42} 100.00%\n",
      "\tAccuracy 100.00%\n",
      "Penicillin Procaine\n",
      "\tSensitivity {'total': 49, 'correct': 48} 97.96%\n",
      "\tSpecificity {'total': 39, 'correct': 39} 100.00%\n",
      "\tAccuracy 98.98%\n",
      "Sensitivity Total 262/264  99.24%\n",
      "Specificity Total 218/220  99.09%\n",
      "Accuracy Total 99.17%\n"
     ]
    }
   ],
   "source": [
    "sensitiv_total=0\n",
    "specific_total=0\n",
    "num_good_cards=0\n",
    "num_bad_cards=0\n",
    "\n",
    "for r in res_good_cards:\n",
    "    sensitivity = 100*res_good_cards[r]['correct']/res_good_cards[r]['total']\n",
    "    specificity = 100*res_bad_cards[r]['correct']/res_bad_cards[r]['total']\n",
    "    \n",
    "\n",
    "    sensitiv_total+=res_good_cards[r]['correct']\n",
    "    specific_total+=res_bad_cards[r]['correct']\n",
    "    \n",
    "    num_good_cards+=res_good_cards[r]['total']\n",
    "    num_bad_cards+= res_bad_cards[r]['total']\n",
    "    \n",
    "    print(dict_sample_name[r])\n",
    "    print(\"\\tSensitivity %s %.2f%s\" % (res_good_cards[r], sensitivity, \"%\"))\n",
    "    print(\"\\tSpecificity %s %.2f%s\" % (res_bad_cards[r], specificity, \"%\"))\n",
    "    print(\"\\tAccuracy %.2f%s\" % ((sensitivity+specificity)/2, \"%\")) \n",
    "\n",
    "s1 = 100*sensitiv_total/num_good_cards\n",
    "s2 = 100*specific_total/num_bad_cards\n",
    "\n",
    "print(\"Sensitivity Total %d/%d  %.2f%s\" % (sensitiv_total, num_good_cards,s1, \"%\"))\n",
    "print(\"Specificity Total %d/%d  %.2f%s\" % (specific_total, num_bad_cards,s2, \"%\"))\n",
    "print(\"Accuracy Total %.2f%s\" % ((s1 + s2)/2, \"%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
